{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab4e8553-d4ac-48d8-8e50-8bccbbc2c430",
   "metadata": {},
   "source": [
    "# Week-11: Tutorial on Pandas (Continued)\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "This week, we will continue learning `pandas`.\n",
    "Before delving into new lecture notes, I will revisit Quiz 3.\n",
    "Comments related to your final project task 1 have been posted, please address them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71db530d-d251-44a9-b627-078c4e89c80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evergarden\\Documents\\GitHub\\BIOS-584\n"
     ]
    }
   ],
   "source": [
    "# 0.1\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "634620a6-3467-4ab8-ad9a-21586bbba160",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsd_dir = '{}/data/PTSD dataset.xlsx'.format(os.getcwd())\n",
    "ptsd_df = pd.read_excel(ptsd_dir, sheet_name='main_dataset')\n",
    "# print(ptsd_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb99242-1a6b-4162-8a9a-840681198527",
   "metadata": {},
   "source": [
    "## 5. Cleaning data using pandas \n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Data cleaning is one of the most common but important tasks in data science.\n",
    "* Pandas allows you to preprocess data for multiple uses, including but not limited to training machine learning and deep learning models.\n",
    "* Always check the missingness of the dataset first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0008a02-2a80-472a-ac04-02abc803b21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record_id              0\n",
       "ptsdpresent_caps       0\n",
       "caps_minuspcl          0\n",
       "caps_minuspcl_code     0\n",
       "caps_intake            0\n",
       "                      ..\n",
       "marines               11\n",
       "navy                  11\n",
       "coastguard            11\n",
       "nationalguard         11\n",
       "reserve               11\n",
       "Length: 439, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.0.1\n",
    "ptsd_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa28e5-7006-4741-833f-cf83d91d165e",
   "metadata": {},
   "source": [
    "### 5.1. Dropping missing values\n",
    "<font size='4'>\n",
    "    \n",
    "* One way to deal with missing data is to simply drop it.\n",
    "* This may be useful when you have plenty of data and losing a small portion won't impact the downstream analysis.\n",
    "* You can use a `.dropna()` method.\n",
    "* As an example, we apply this method to a copy of original dataset.\n",
    "* https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fef0893f-586e-4712-a286-9b9f7e3ad1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1.1\n",
    "\n",
    "ptsd_df_2 = ptsd_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f570a0-d13f-4db7-8fe8-627b71658650",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* The resulting `ptsd_df_2` ends up with no rows because `dropna()` will remove the entire row as long as there exists one missing value.\n",
    "* Let's look at the dataset with its first eight columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bbc3084-1a13-4bf5-9457-8fde5a0a169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 8)\n"
     ]
    }
   ],
   "source": [
    "# 5.1.2\n",
    "ptsd_df_3 = ptsd_df.copy()\n",
    "ptsd_df_3 = ptsd_df.iloc[:,range(8)]\n",
    "ptsd_df_3.dropna()\n",
    "print(ptsd_df_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7dbec-c4ca-40a3-b25d-9fd6f6d77d11",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* The original sample size is reduced from 483 to 450.\n",
    "* When one variable has the missingness smaller than **10%**, it is okay to simply remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361ef653-8e56-496f-b188-7ce28fae4686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1.3\n",
    "ptsd_df_4 = ptsd_df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c6d84-a4e1-40be-849e-1bb9d88c9597",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "    \n",
    "* The `axis` parameter lets you specify whether you are dropping rows, or columns, with missing values.\n",
    "    * The default `axis` removes the rows containing `NaN`.\n",
    "    * For a two-dimensional array, use `axis=1` to remove the columns with one or more `NaN` values.\n",
    "    * `inplace=True` lets you skip saving the output of `.dropna()` into a new DataFrame.\n",
    "* In this case, the column number is reduced from 439 to 71.\n",
    "\n",
    "* Of couse, we can drop both rows and columns with missing values by setting the `how` parameter.\n",
    "    * `any`: If any missing values are present, drop that row or column.\n",
    "    * `all`: If all values are NA, drop that row or column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b69887-9888-4319-9380-8112a0f5630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1.4\n",
    "\n",
    "# In this case, when we set `all`, \n",
    "# nothing is reduced because there is no completely missing row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede0d19-f192-4dfd-aa15-4f8721dec136",
   "metadata": {},
   "source": [
    "### 5.2. Replacing missing values\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* When the missing percentage is moderate (>= 15% in my view), dropping values may lose information and introduce bias to your effect estimation.\n",
    "* Replacing missing values with other values is preferred.\n",
    "* You can fill in the missing values with a summary statistics, i.e., mean value, or apply some statistical methodology to infer a number, i.e., multiple imputation.\n",
    "* Relevant pandas method is named `.fillna()`.\n",
    "* https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fef7af6-b247-445f-94bf-7df9c3dcc7b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pc15month_score.baseline'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\BIOS-584\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'pc15month_score.baseline'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m ptsd_df_3 = ptsd_df.iloc[:,\u001b[38;5;28mrange\u001b[39m(\u001b[32m8\u001b[39m)]\n\u001b[32m      4\u001b[39m ptsd_df_3.isnull().sum()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m pc15baseline_mean =  \u001b[43mptsd_df_3\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpc15month_score.baseline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, mean()\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# print(pc15baseline_mean)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\BIOS-584\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\BIOS-584\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'pc15month_score.baseline'"
     ]
    }
   ],
   "source": [
    "# 5.2.1\n",
    "ptsd_df_3 = ptsd_df.copy()\n",
    "ptsd_df_3 = ptsd_df.iloc[:,range(8)]\n",
    "#finds missing values\n",
    "ptsd_df_3.isnull().sum()\n",
    "\n",
    "pc15baseline_mean =  ptsd_df_3[\"pc15month_score.baseline\"], mean()\n",
    "# print(pc15baseline_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eed1de2c-9201-43b6-9043-ceda81baf8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2.2\n",
    "# Assign the mean of pcl5week_score.completion to its 27 missing values.\n",
    "# Write down your code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982566b0-1e5d-4a9b-b7b4-121c2fd5c9d7",
   "metadata": {},
   "source": [
    "### 5.3. Handling Duplicated Values\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Let's manually create some duplicates to the existing dataset.\n",
    "* You can remove all duplicated rows (by default) from the DataFrame using `.drop_duplicates()` method.\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7088813-4106-4eee-a107-49d3522f49f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     record_id  ptsdpresent_caps  caps_minuspcl  caps_minuspcl_code  \\\n",
      "0          460                 1            -56                   1   \n",
      "1         5942                 1            -49                   1   \n",
      "2         5366                 1            -48                   1   \n",
      "3         3480                 1            -47                   1   \n",
      "4         1029                 1            -46                   1   \n",
      "..         ...               ...            ...                 ...   \n",
      "478       1922                 1             13                   3   \n",
      "479       2427                 1             21                   3   \n",
      "480        179                 1             21                   3   \n",
      "481       3533                 1             24                   3   \n",
      "482       3021                 1             30                   3   \n",
      "\n",
      "     caps_intake  pcl5_score_intake  pcl5month_score.baseline  \\\n",
      "0             15                 71                      75.0   \n",
      "1             23                 72                       NaN   \n",
      "2             31                 79                      62.0   \n",
      "3             31                 78                      76.0   \n",
      "4             28                 74                      52.0   \n",
      "..           ...                ...                       ...   \n",
      "478           44                 31                      34.0   \n",
      "479           42                 21                      45.0   \n",
      "480           38                 17                      17.0   \n",
      "481           38                 14                      35.0   \n",
      "482           42                 12                      66.0   \n",
      "\n",
      "     pcl5week_score.completion  \n",
      "0                         40.0  \n",
      "1                         52.0  \n",
      "2                         23.0  \n",
      "3                         72.0  \n",
      "4                         29.0  \n",
      "..                         ...  \n",
      "478                       25.0  \n",
      "479                       13.0  \n",
      "480                        NaN  \n",
      "481                       25.0  \n",
      "482                       74.0  \n",
      "\n",
      "[483 rows x 8 columns]\n",
      "     record_id  ptsdpresent_caps  caps_minuspcl  caps_minuspcl_code  \\\n",
      "0          460                 1            -56                   1   \n",
      "1         5942                 1            -49                   1   \n",
      "2         5366                 1            -48                   1   \n",
      "3         3480                 1            -47                   1   \n",
      "4         1029                 1            -46                   1   \n",
      "..         ...               ...            ...                 ...   \n",
      "478       1922                 1             13                   3   \n",
      "479       2427                 1             21                   3   \n",
      "480        179                 1             21                   3   \n",
      "481       3533                 1             24                   3   \n",
      "482       3021                 1             30                   3   \n",
      "\n",
      "     caps_intake  pcl5_score_intake  pcl5month_score.baseline  \\\n",
      "0             15                 71                      75.0   \n",
      "1             23                 72                       NaN   \n",
      "2             31                 79                      62.0   \n",
      "3             31                 78                      76.0   \n",
      "4             28                 74                      52.0   \n",
      "..           ...                ...                       ...   \n",
      "478           44                 31                      34.0   \n",
      "479           42                 21                      45.0   \n",
      "480           38                 17                      17.0   \n",
      "481           38                 14                      35.0   \n",
      "482           42                 12                      66.0   \n",
      "\n",
      "     pcl5week_score.completion  \n",
      "0                         40.0  \n",
      "1                         52.0  \n",
      "2                         23.0  \n",
      "3                         72.0  \n",
      "4                         29.0  \n",
      "..                         ...  \n",
      "478                       25.0  \n",
      "479                       13.0  \n",
      "480                        NaN  \n",
      "481                       25.0  \n",
      "482                       74.0  \n",
      "\n",
      "[966 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# 5.3.1\n",
    "ptsd_df_3_dup = pd.concat([ptsd_df_3, ptsd_df_3])\n",
    "print(ptsd_df_3)\n",
    "print(ptsd_df_3_dup)\n",
    "# number of rows doubles while the columns stays the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04c1a7a6-a809-4026-809a-c9928e1586c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3.2\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96163f-86b4-41a2-83bf-867047be35f7",
   "metadata": {},
   "source": [
    "### 5.4. Renaming Columns\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* You can use `.rename()` method to modify the column names.\n",
    "* For example, we want to change `pcl5month_score.baseline` to `pcl5_score_baseline` and `pcl5week_score.completion` to `pcl5_score_completion` in `ptsd_df_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed351449-e982-4760-bbdb-e74c88ab33d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b89abc-6b4a-4efe-9818-50d4f2e4f326",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* You can also directly assign column names as a list to the DataFrame.\n",
    "* Make sure the variable order in the list is consistent with the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c628536e-fbf7-4d32-8821-f9cbcefcaa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756ef6d-7647-48ef-bbbf-fd41ffbffda1",
   "metadata": {},
   "source": [
    "<font size='4'>\n",
    "\n",
    "* For more details, please read this checklist: https://www.datacamp.com/blog/infographic-data-cleaning-checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f0d04-3d38-4e0d-9e8f-631435d70724",
   "metadata": {},
   "source": [
    "## 6. Data Analysis in Pandas\n",
    "\n",
    "### 6.1. Summary Statistics (mean, median, and mode)\n",
    "\n",
    "<font size='4'>\n",
    "    \n",
    "* `.mean()` for mean\n",
    "* `.median()` for median\n",
    "* `.mode()` for mode\n",
    "\n",
    "* Similar to `np.mean(), np.median()` functions, Pandas has three methods to compute mean, median, and mode for the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd1af50-d311-4549-b575-7a36a3454aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1.1\n",
    "\n",
    "# However, this only applies to continuous or ordinal columns. You need to check your results carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ddd6b-ddb6-4c81-b543-66d62727ad7f",
   "metadata": {},
   "source": [
    "### 6.2. Create new columns based on existing columns\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Similar to R, pandas can easily create a new column using data from existing columns.\n",
    "* For example, let's create a new column `pcl_5_mean` by taking the average of `pcl_5_score_intake`, `pcl_5_score_baseline`, and `pcl_5_score_completion`.\n",
    "    * This value is not clinically meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bde2516f-636a-408a-a87d-b60c8af4a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cfac13-c30c-4a90-864e-bccdbb351876",
   "metadata": {},
   "source": [
    "### 6.3. Counting using `.value_counts()`\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* For categorical variables, we use `.value_counts()` method\n",
    "* https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78d4c4ac-e265-4fdc-8d97-368e42713fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83e80f-893a-43d9-9277-37d6b7415df6",
   "metadata": {},
   "source": [
    "### 6.4. Aggregating data with `.groupby()` in pandas\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Pandas allows you to aggregate values by grouping them by specific column values using `.groupby()` method.\n",
    "* Pay attention to the order of your methods.\n",
    "* Use `[]` to include multiple variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e46b292a-1fa0-4dc4-99a1-33c88ce31b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d59e7498-7b6b-4e27-8f7e-44c12f9036af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aedb3c6-5bab-4654-a300-79047aee67d3",
   "metadata": {},
   "source": [
    "### 6.5. Pivot tables\n",
    "\n",
    "<font size='4'>\n",
    "\n",
    "* Pandas enables you to calculate summary statistics as pivot tables.\n",
    "* Use `pandas.pivot_table()` function\n",
    "* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html\n",
    "* `index` is the row variable, `columns` is  the column variable, `values` are the outcome of interest after aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "525b30ba-4af4-44a6-8971-be6f2603164c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">pcl5month_score.baseline</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pcl5week_score.completion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_code</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caps_minuspcl_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.458333</td>\n",
       "      <td>63.030303</td>\n",
       "      <td>34.765957</td>\n",
       "      <td>36.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.541667</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>30.659341</td>\n",
       "      <td>28.467742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.500000</td>\n",
       "      <td>37.360000</td>\n",
       "      <td>21.422222</td>\n",
       "      <td>20.640000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pcl5month_score.baseline             \\\n",
       "gender_code                               1          2   \n",
       "caps_minuspcl_code                                       \n",
       "1                                 58.458333  63.030303   \n",
       "2                                 51.541667  51.500000   \n",
       "3                                 40.500000  37.360000   \n",
       "\n",
       "                   pcl5week_score.completion             \n",
       "gender_code                                1          2  \n",
       "caps_minuspcl_code                                       \n",
       "1                                  34.765957  36.363636  \n",
       "2                                  30.659341  28.467742  \n",
       "3                                  21.422222  20.640000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.5.1\n",
    "pd.pivot_table(ptsd_df, \n",
    "               values = ['pcl5week_score.completion', 'pcl5month_score.baseline'],\n",
    "               index = 'caps_minuspcl_code',\n",
    "               columns = ['gender_code'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e29af9ef-76b7-4d17-8075-09ea76553dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5.2\n",
    "# You can examine multiple outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a665c77a-d9fd-4b02-8ab0-807197a006b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5.3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
